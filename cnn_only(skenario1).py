# -*- coding: utf-8 -*-
"""cnn_only.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zwsyiavluRxYl0ogJRn5aVVNuXGLct4q
"""

from google.colab import drive
import os

drive.mount('/content/drive')
path = '/content/drive/MyDrive/shape_dataset'
os.listdir(path)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

# =========================
# PARAMETER
# =========================
IMG_SIZE = (56, 56)
BATCH_SIZE = 20
EPOCHS = 100

TRAIN_DIR = r''+path+'/train224'   # folder data training
TEST_DIR  = r''+path+'/test224'

# =========================
# DATA GENERATOR (GRAYSCALE)
# =========================
train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen  = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMG_SIZE,
    color_mode="grayscale",     # ⬅️ konversi grayscale
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

val_generator = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMG_SIZE,
    color_mode="grayscale",     # ⬅️ konversi grayscale
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False
)

NUM_CLASSES = train_generator.num_classes
print("Jumlah kelas:", NUM_CLASSES)

# =========================
# MODEL CNN (1 CHANNEL)
# =========================
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(56,56,1)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),

    Dense(NUM_CLASSES, activation='softmax')
])

# =========================
# COMPILE
# =========================
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# =========================
# CALLBACK
# =========================
checkpoint = ModelCheckpoint(
    "best_model_grayscale_no_aug.h5",
    monitor="val_accuracy",
    save_best_only=True,
    verbose=1
)

early_stop = EarlyStopping(
    monitor="val_loss",
    patience=8,
    restore_best_weights=True
)

# =========================
# TRAINING
# =========================
history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    callbacks=[checkpoint]
)

print("Training selesai. Model terbaik disimpan.")

import shutil

src = "/content/best_model_grayscale_no_aug.h5"
dst = "/content/drive/MyDrive/shape_dataset/best_model_grayscale_no_aug.h5"

shutil.copy(src, dst)

print("Model berhasil disalin ke Google Drive")

from tensorflow.keras.models import load_model

MODEL_PATH = "/content/drive/MyDrive/shape_dataset/best_model_grayscale_no_aug_72.h5"

val_generator = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMG_SIZE,
    color_mode="grayscale",     # ⬅️ konversi grayscale
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False
)

model = load_model(MODEL_PATH)
print("Model berhasil dimuat")

import numpy as np

y_pred_prob = model.predict(val_generator)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = val_generator.classes

from sklearn.metrics import accuracy_score

acc = accuracy_score(y_true, y_pred)
print("Test Accuracy:", acc)

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model

# =========================
# LOAD MODEL
# =========================
model = load_model("/content/drive/MyDrive/shape_dataset/best_model_grayscale_no_aug_72.h5")

# =========================
# PREDIKSI DATA TEST
# =========================
y_pred_prob = model.predict(val_generator)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = val_generator.classes

filepaths = val_generator.filepaths
labels = list(val_generator.class_indices.keys())

# =========================
# BUAT DATAFRAME HASIL
# =========================
results_df = pd.DataFrame({
    "filename": [os.path.basename(f) for f in filepaths],
    "true_label": [labels[i] for i in y_true],
    "pred_label": [labels[i] for i in y_pred]
})

results_df["status"] = np.where(
    results_df["true_label"] == results_df["pred_label"],
    "BENAR",
    "SALAH"
)

# =========================
# TAMPILKAN RINGKASAN
# =========================
print("Jumlah BENAR :", (results_df["status"] == "BENAR").sum())
print("Jumlah SALAH :", (results_df["status"] == "SALAH").sum())

print("\nContoh BENAR:")
display(results_df[results_df["status"] == "BENAR"].head(5))

print("\nContoh SALAH:")
display(results_df[results_df["status"] == "SALAH"].head(5))

# =========================
# SIMPAN KE CSV (OPSIONAL)
# =========================
results_df.to_csv(
    "/content/drive/MyDrive/shape_dataset/hasil_prediksi_test.csv",
    index=False
)

# =========================
# VISUALISASI GAMBAR SALAH
# =========================
wrong = results_df[results_df["status"] == "SALAH"]

plt.figure(figsize=(12,8))
for i, idx in enumerate(wrong.index[:9]):
    img = plt.imread(filepaths[idx])
    plt.subplot(3,3,i+1)
    plt.imshow(img, cmap="gray")
    plt.title(
        f"True: {wrong.loc[idx,'true_label']}\nPred: {wrong.loc[idx,'pred_label']}",
        fontsize=9
    )
    plt.axis("off")

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix,
    classification_report,
    accuracy_score,
    precision_recall_fscore_support
)

# =========================
# CONFUSION MATRIX
# =========================
cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(6,5))
sns.heatmap(
    cm,
    annot=True,
    fmt='d',
    cmap='Blues',
    xticklabels=labels,
    yticklabels=labels
)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.show()

# =========================
# METRIK UTAMA
# =========================
accuracy = accuracy_score(y_true, y_pred)

precision, recall, f1, _ = precision_recall_fscore_support(
    y_true,
    y_pred,
    average='macro'   # ⬅️ adil untuk multi-class
)

print("=== METRIK GLOBAL (MACRO) ===")
print(f"Accuracy : {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall   : {recall:.4f}")
print(f"F1-score : {f1:.4f}")

# =========================
# DETAIL PER KELAS
# =========================
print("\n=== CLASSIFICATION REPORT ===")
print(classification_report(
    y_true,
    y_pred,
    target_names=labels,
    digits=4
))